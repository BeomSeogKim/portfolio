# :pushpin: 우.이.삭 (우리 이거 삭제하지 말자)
> 커플 기반 다이어리 서비스  
> 🔗 [Service](https://woisac.netlify.app/)   
> 🔗 [Backend API](https://love-back.kro.kr/docs/index.html)

</br>

## 1. 제작 기간 & 참여 인원
- 2023년 10월 12일 ~ 2023년 12월 04일
- 팀 프로젝트
  - [FrontEnd] : 김정호(팀장), 홍건우, 조수연
  - [BackEnd]  : 김범석(팀장), 김도연, 김재웅 

</br>

## 2. 사용 기술
#### `Backend`
  - Java 17, Spring Boot 3.1, MySQL 8.0, H2
  - Spring Data JPA, QueryDSL
  - Spring HATEOAS
  - Spring OAUTH2 Client, JWT
  - Spring REST Docs
  - Junit5, Mockito, ArchUnit, Ngrinder
  - Prometheus, Spring Actuator
  - flyway, caffeine

</br>

## 3. ERD 설계

<img src="https://github.com/BeomSeogKim/portfolio/assets/110332047/e0dc3e73-43fd-4f9d-9728-968a2f5377d1" alt="대체 텍스트" width="1500" height="600">

   
## 4. 핵심 기능
이 서비스의 핵심 기능은 다이어리 기능입니다.  
다이어리는 카카오맵 기반으로 작성을 합니다.  
다이어리 조희 경우 총 네가지 조회 기능을 제공합니다.   
1. 카카오 맵에서 보여지는 다이어리 리스트 조회
2. 특정 장소 다이어리 리스트 조회
3. 커플이 작성한 다이어리 리스트 조회
4. 다이어리 상세 조회

<details>
  <summary>지도 예시</summary>

  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/5057c922-e007-4569-bff7-ea509bac48b8)

</details>


<details>
  <summary>Infra</summary>

  ![image](https://github.com/Lovely-4K/love-backend/assets/110332047/cf61aaed-5b45-433b-bc0d-bcaf0a8c80ab)

</details>

<details>
  <summary>CI / CD</summary>

  ![image](https://github.com/Lovely-4K/love-backend/assets/110332047/14e62846-d571-4a63-b162-97f1d18de477)

</details>

</br>

## 5. 서비스 개선 사항
> 각 개선 사항에 대해 토글을 클릭하시면 자세한 내용을 확인 하실 수 있습니다.  

<details>
  <summary> SQL 튜닝 </summary>

  </br>
  <details>
  <summary> 다이어리 목록 조회 쿼리 개선 </summary>

  다이어리 목록 조회의 경우 데이트 날짜 기준으로 최근순으로 조회하는 쿼리를 제일 많이 사용합니다.  
  해당 쿼리는 다음과 같습니다. 
  ```sql
  SELECT d.id, l.kakao_map_id, d.first_image, d.dating_day, l.place_name,
         l.address, l.latitude, l.longitude
  FROM diary d
           LEFT JOIN location l ON l.id = d.location_id
  WHERE d.couple_id = 1
  ORDER BY d.dating_day DESC
  LIMIT 20 OFFSET 0;
  ```
  튜닝 전의 실행 계획과 분석 결과는 다음과 같았습니다.
  <details>
  <summary>기존</summary>
  
  ```sql
  -> Limit: 20 row(s)  (cost=6196 rows=20) (actual time=10.7..10.8 rows=20 loops=1)
      -> Nested loop left join  (cost=6196 rows=12110) (actual time=10.7..10.8 rows=20 loops=1)
          -> Sort: d.dating_day DESC, limit input to 20 row(s) per chunk  (cost=1957 rows=12110) (actual time=10.7..10.7 rows=20 loops=1)
      -> Index lookup on d using idx_diary_couple_id (couple_id=1)  (cost=1957 rows=12110) (actual time=0.2..9.67 rows=6729 loops=1)
      -> Single-row index lookup on l using PRIMARY (id=d.location_id)  (cost=0.25 rows=1) (actual time=0.00262..0.00265 rows=1 loops=20)
  ```

  | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
  | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
  | 1 | SIMPLE | d | null | ref | idx_diary_couple_id | idx_diary_couple_id | 9 | const | 12110 | 100 | Using filesort |
  | 1 | SIMPLE | l | null | eq_ref | PRIMARY | PRIMARY | 8 | love.d.location_id | 1 | 100 | null |
  </details>
  
  Using filesort의 경우 row가 많아질 수록 성능이 떨어진다는 단점이 존재합니다. 따라서 Covering Index를 적용해주었습니다.   
  
  `CREATE INDEX  idx_couple_id_dating_day ON diary(dating_day, couple_id);`

  <details>
    <summary>1차 성능 튜닝</summary>

    ```sql
    -> Limit: 20 row(s)  (cost=3031 rows=19.9) (actual time=0.21..6.54 rows=20 loops=1)
    -> Nested loop left join  (cost=3031 rows=19.9) (actual time=0.209..6.54 rows=20 loops=1)
        -> Filter: (d.couple_id = 1)  (cost=1.23 rows=19.9) (actual time=0.198..6.48 rows=20 loops=1)
            -> Index scan on d using idx_couple_id_dating_day (reverse)  (cost=1.23 rows=157) (actual time=0.19..6.33 rows=2405 loops=1)
        -> Single-row index lookup on l using PRIMARY (id=d.location_id)  (cost=0.25 rows=1) (actual time=0.00282..0.00286 rows=1 loops=20)
    ```

  | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
  | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
  | 1 | SIMPLE | d | null | index | idx_diary_couple_id | idx_couple_id_dating_day | 13 | null | 157 | 12.68 | Using where; Backward index scan |
  | 1 | SIMPLE | l | null | eq_ref | PRIMARY | PRIMARY | 8 | love.d.location_id | 1 | 100 | null |
  </details>

  조회로직의 경우 보통 최근순으로 조회하기 때문에 Using Backward index scan이 걸리는 것을 확인할 수 있었습니다.  
  이에 따라 데이트 날짜 정렬 조건을 내림차순으로 변경후 인덱스를 생성해 주었습니다.   
  
  `CREATE INDEX  idx_couple_id_dating_day ON diary(dating_day DESC , couple_id);`

  <details>
    <summary>2차 성능 튜닝</summary>

    ```sql
    -> Limit: 20 row(s)  (cost=3031 rows=19.9) (actual time=0.214..0.43 rows=20 loops=1)
    -> Nested loop left join  (cost=3031 rows=19.9) (actual time=0.213..0.428 rows=20 loops=1)
        -> Filter: (d.couple_id = 1)  (cost=1.23 rows=19.9) (actual time=0.202..0.376 rows=20 loops=1)
            -> Index scan on d using idx_couple_id_dating_day  (cost=1.23 rows=157) (actual time=0.199..0.362 rows=188 loops=1)
        -> Single-row index lookup on l using PRIMARY (id=d.location_id)  (cost=0.25 rows=1) (actual time=0.00231..0.00235 rows=1 loops=20)
    ```

  | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
  | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
  | 1 | SIMPLE | d | null | index | idx_diary_couple_id | idx_couple_id_dating_day | 13 | null | 157 | 12.68 | Using where |
  | 1 | SIMPLE | l | null | eq_ref | PRIMARY | PRIMARY | 8 | love.d.location_id | 1 | 100 | null |
  </details>

  기존 쿼리와 튜닝 후 성능 개선사항은 다음과 같습니다. 
  | 성능 지표 | 튜닝 전 | 튜닝 후 | 성능 개선 (%) |
  | --- | --- | --- | --- |
  |총 수행시간 (ms) | 10.8 | 0.43 | 96.02 |
  | 처리 행 수 | 12,110 | 19.9 | 99.84 |
  </details>

  </br>
  
  <details>
  <summary>다이어리 마커 조회 쿼리 개선</summary>
  다이어리 마커 조회란 동일한 장소에 해당하는 다이어리 목록들을 조회할 때 사용하는 기능입니다.

  해당 쿼리는 다음과 같습니다. 
  ```sql
  SELECT d1_0.id, d1_0.boy_text, d1_0.couple_id, d1_0.created_at, d1_0.dating_day,
         d1_0.girl_text, l1_0.id, l1_0.address, l1_0.category, l1_0.created_at,
         l1_0.kakao_map_id, l1_0.latitude, l1_0.longitude, l1_0.updated_at, l1_0.place_name,
         d1_0.updated_at, d1_0.fifth_image, d1_0.first_image, d1_0.fourth_image, d1_0.second_image,
         d1_0.third_image, d1_0.score
  FROM diary d1_0
           JOIN location l1_0 ON l1_0.id = d1_0.location_id
  WHERE l1_0.kakao_map_id = 10978
    AND d1_0.couple_id = 1;
  ```

  튜닝 전의 실행 계획과 분석 결과는 다음과 같았습니다.
  
  <details>
    <summary>기존</summary>
    
    ```sql
    -> Nested loop inner join  (cost=6192 rows=605) (actual time=28.4..28.6 rows=23 loops=1)
        -> Filter: (d1_0.location_id is not null)  (cost=1956 rows=12102) (actual time=0.0299..14.3 rows=6725 loops=1)
            -> Index lookup on d1_0 using idx_diary_couple_id (couple_id=1)  (cost=1956 rows=12102) (actual time=0.0284..13.7 rows=6725 loops=1)
        -> Filter: (l1_0.kakao_map_id = 10978)  (cost=0.25 rows=0.05) (actual time=0.00199..0.00199 rows=0.00342 loops=6725)
            -> Single-row index lookup on l1_0 using PRIMARY (id=d1_0.location_id)  (cost=0.25 rows=1) (actual time=0.00175..0.00178 rows=1 loops=6725)
    ```
  
  | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
  | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
  | 1 | SIMPLE | d1_0 | null | ref | idx_diary_couple_id | idx_diary_couple_id | 9 | const | 12102 | 100 | Using where |
  | 1 | SIMPLE | l1_0 | null | eq_ref | PRIMARY,idx_lacation_kakao_map_id | PRIMARY | 8 | love.d1_0.location_id | 1 | 5 | Using where |
  </details>

  diary 특성 중 location_id와 couple_id가 자주 사용되는 것을 확인하여 다음과 같이 인덱스를 생성해 주었습니다. 

  `CREATE INDEX idx_location_couple ON diary(location_id, couple_id);`

  <details>
    <summary>성능 튜닝 후</summary>
  
    ```sql
    -> Nested loop inner join  (cost=28 rows=40) (actual time=0.884..0.996 rows=23 loops=1)
      -> Index lookup on l1_0 using idx_lacation_kakao_map_id (kakao_map_id=10978)  (cost=14 rows=40) (actual time=0.145..0.159 rows=40 loops=1)
      -> Index lookup on d1_0 using idx_location_couple (location_id=l1_0.id, couple_id=1)  (cost=0.253 rows=1) (actual time=0.0203..0.0207 rows=0.575 loops=40)
    ```
  
  | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
  | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
  | 1 | SIMPLE | l1_0 | null | ref | PRIMARY,idx_lacation_kakao_map_id | idx_lacation_kakao_map_id | 9 | const | 40 | 100 | null |
  | 1 | SIMPLE | d1_0 | null | ref | idx_diary_couple_id,idx_location_couple | idx_location_couple | 18 | love.l1_0.id,const | 1 | 100 | null |
  </details>

  기존 쿼리와 성능 튜닝 후 성능 개선사항은 다음과 같습니다. 
  | 성능 지표 | 튜닝 전 | 튜닝 후 | 성능 개선 (%) |
  | --- | --- | --- | --- |
  |총 수행시간 (ms) | 28.6 | 0.996 | 96.52 |
  | 처리 행 수 | 12,102 | 40 | 99.67 |
</details>

</br>

<details>
  <summary>다이어리 지도 조회 쿼리 개선</summary>

  다이어리 지도 조회의 경우 ui에서 보이는 지도 안에 존재하는 다이어리 목록을 조회하는 쿼리를 사용합니다.
  해당 쿼리는 다음과 같습니다.

  ```sql
  SELECT d.id, d.boy_text, d.couple_id, d.created_at, d.dating_day,
       d.girl_text, l.id, l.address, l.category, l.created_at,
       l.kakao_map_id, l.latitude, l.longitude, l.updated_at, l.place_name,
       d.updated_at, d.fifth_image, d.first_image, d.fourth_image, d.second_image,
       d.third_image, d.score
  FROM diary d
         JOIN location l ON l.id = d.location_id
  WHERE d.couple_id = 1
    AND 90.0 <= l.latitude <= 91.0
    AND 90.0 <= l.longitude <= 91.0;
  ```

튜닝 전의 실행 계획과 분석 결과는 다음과 같았습니다.

<details>
  <summary>기존</summary>
  
  ```sql
  -> Nested loop inner join  (cost=6192 rows=12102) (actual time=0.0396..32.6 rows=6725 loops=1)
    -> Filter: (d.location_id is not null)  (cost=1956 rows=12102) (actual time=0.0261..15.5 rows=6725 loops=1)
        -> Index lookup on d using idx_diary_couple_id (couple_id=1)  (cost=1956 rows=12102) (actual time=0.025..14.9 rows=6725 loops=1)
    -> Filter: (((90.0000000 <= l.latitude) <= 91.0) and ((90.0000000 <= l.longitude) <= 91.0))  (cost=0.25 rows=1) (actual time=0.00224..0.00235 rows=1 loops=6725)
        -> Single-row index lookup on l using PRIMARY (id=d.location_id)  (cost=0.25 rows=1) (actual time=0.00184..0.00187 rows=1 loops=6725)
  ```

| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | SIMPLE | d | null | ref | idx_diary_couple_id,idx_location_couple | idx_diary_couple_id | 9 | const | 12102 | 100 | Using where |
| 1 | SIMPLE | l | null | eq_ref | PRIMARY | PRIMARY | 8 | love.d.location_id | 1 | 100 | Using where |
</details>

특정 범위에 있는 결과값을 찾을 때 효과적이지 못한 쿼리로 조회하는 것을 확인했으며 1차적으로 쿼리 변경을 진행했습니다.  

관련 쿼리는 다음과 같습니다.  

```sql
SELECT d.id, d.boy_text, d.couple_id, d.created_at, d.dating_day,
       d.girl_text, l.id, l.address, l.category, l.created_at,
       l.kakao_map_id, l.latitude, l.longitude, l.updated_at, l.place_name,
       d.updated_at, d.fifth_image, d.first_image, d.fourth_image, d.second_image,
       d.third_image, d.score
FROM diary d
         JOIN location l ON l.id = d.location_id
WHERE d.couple_id = 1
  AND l.latitude BETWEEN 90.0 AND 91.0
  AND l.longitude BETWEEN 100.0 AND 101.0;
```

쿼리 변경후 결과는 다음과 같았습니다. 

<details>
  <summary>1차 성능 튜닝</summary>

  ```sql
  -> Nested loop inner join  (cost=6192 rows=605) (actual time=28.9..29 rows=24 loops=1)
    -> Filter: (d.location_id is not null)  (cost=1956 rows=12102) (actual time=0.0278..14.3 rows=6725 loops=1)
        -> Index lookup on d using idx_diary_couple_id (couple_id=1)  (cost=1956 rows=12102) (actual time=0.0267..13.7 rows=6725 loops=1)
    -> Filter: ((l.latitude between 90.0 and 91.0) and (l.longitude between 100.0 and 101.0))  (cost=0.25 rows=0.05) (actual time=0.00207..0.00207 rows=0.00357 loops=6725)
        -> Single-row index lookup on l using PRIMARY (id=d.location_id)  (cost=0.25 rows=1) (actual time=0.00173..0.00177 rows=1 loops=6725)
  ```

| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | SIMPLE | d | null | ref | idx_diary_couple_id,idx_location_couple | idx_diary_couple_id | 9 | const | 12102 | 100 | Using where |
| 1 | SIMPLE | l | null | eq_ref | PRIMARY | PRIMARY | 8 | love.d.location_id | 1 | 5 | Using where |
</details>

location의 latitude, longitude 영역에 대해서 인덱스가 없기 때문에 Using where 조건을 사용하는 것을 확인 할 수 있었습니다. 

해당 부분을 해결하기 위해 다음과 같이 인덱스를 생성해 주었습니다. 

`CREATE INDEX*  idx_location_latitude_longitude *ON* location(latitude, longitude);`

<details>
  <summary>2차 성능 튜닝</summary>

  ```sql
  -> Nested loop inner join  (cost=23.9 rows=41) (actual time=0.0687..0.369 rows=24 loops=1)
    -> Index range scan on l using idx_location_latitude_longitude  (cost=18.7 rows=41) (actual time=0.0423..0.185 rows=41 loops=1)
        - Over: 90.0000000 <= latitude <= 91.0000000 AND 100.0000000 <= longitude <= 101.0000000
        - With index condition: ((l.latitude between 90.0 and 91.0) and (l.longitude between 100.0 and 101.0))
    -> Index lookup on d using idx_location_couple (location_id=l.id, couple_id=1)  (cost=0.272 rows=1) (actual time=0.00376..0.00424 rows=0.585 loops=41)
  ```

| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | SIMPLE | l | null | range | PRIMARY,idx_location_latitude_longitude | idx_location_latitude_longitude | 14 | null | 41 | 11.11 | Using index condition |
| 1 | SIMPLE | d | null | ref | idx_diary_couple_id,idx_location_couple | idx_location_couple | 18 | http://love.l.id/,const | 1 | 100 | null |
</details>

기존 쿼리와 성능 튜닝 후 성능 개선사항은 다음과 같습니다. 
| 성능 지표 | 튜닝 전 | 튜닝 후 | 성능 개선 (%) |
| --- | --- | --- | --- |
|총 수행시간 (ms) | 32.6 | 0.369 | 98.87 |
| 처리 행 수 | 6725 | 24 | 99.64 |

</details>
</br>
</details>


<details> 
  <summary> 어플리케이션 튜닝 </summary>
  
  > ***각 튜닝 별 성능 수치는 토글을 통해 확인을 할 수 있습니다.***
  
  커플 기반 비슷한 서비스를 분석해본 결과 한달에 300만 트래픽을 처리하고 있었습니다.  
  따라서 저희 서비스 또한 해당 트래픽을 목표로 성능 튜닝을 진행했습니다.  
  어플리케이션 사용 시나리오는 다음과 같이 설정했습니다.   
  `로그인 → 프로필 조회 → 프로필 수정 → 다이어리 조회 → 다이어리 조회 → 다이어리 조회 → 다이어리 조회 → 다이어리 작성 → 일정 조회 → 일정 조회 → 일정 생성 → 오늘의 질문 조회`  
  평소에는 초당 9명의 유저가 사용한다고 가정했으며, 붐비는 시간에는 평소 시간대보다 3배의 유저인 27명의 유저가 사용한다고 가정했습니다.

  
  

<details> 
  <summary>기본 설정</summary>
  
  기본 설정의 경우  TPS 및 에러율은 다음과 같았습니다.   
  - Vuser9 : TPS 13.5  |  에러율 : 0.1%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/bb37fa38-b3c8-4e21-be3b-f2eee7d96bff)

  - Vuser27 : TPS 12.8  |  에러율 :  4.4%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/e95e2b60-d48b-40c6-9d0a-ad6e10c7a7f9)

</details>

Vuser 27의 경우 에러율이 급격하게 높아져 모니터링 해본 결과 Connection을 받지 못하고 기다리는 상황이 발생해 Connection Timeout 문제가 발생해 에러율이 급격하게 증가하는 것을 확인했습니다.  
이에 따라 application.yaml파일에서 hikari 관련 설정을 변경을 했습니다. 
```yaml
spring:
  datasource:
    hikari:
      minimum-idle: 10
      maximum-pool-size: 50
```

<details> 
  <summary>Connection Pool 수정 후</summary>
  
  Hikari Connection Pool 수정 후 TPS 및 에러율은 다음과 같았습니다.   
  - Vuser9 : TPS 12.0  |  에러율 : 0.1%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/f72dd2da-abdb-491a-bbe0-378bc34b359d)


  - Vuser27 : TPS 12.4  |  에러율 :  0.1%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/0d281f12-0c54-4316-a93d-222e99d1f98f)

</details>

Hikari Connection Pool 설정 변경 후 에러율은 감소했지만 TPS 자체는 크게 변경되지 않는 것을 확인했습니다.  
보다 높은 TPS를 위해 조회 로직의 경우 캐시를 적용하기로 결정했습니다. Caffeine Cachce를 적용했습니다.

<details> 
  <summary>Cache 적용 후</summary>
  
  Spring Cache 적용 후 TPS 및 에러율은 다음과 같았습니다.   
  - Vuser9 : TPS 133.9  |  에러율 : 0.0%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/a8fadfed-45fc-4c94-aaa5-2032f0a44107)

  - Vuser27 : TPS 156.7  |  에러율 :  0.0%
 ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/a7ce9ef1-f0fe-432c-8844-36a745112320)

  특히 캐시가 변경되지 않는 조회 로직만 테스트 해본 결과는 다음과 같았습니다.
  
  - Vuser27 : TPS 368.8  |  에러율 :  0.0%
  ![image](https://github.com/BeomSeogKim/portfolio/assets/110332047/9e3ec010-ea9d-45c7-b75a-9324e8d789db)

</details>
</br>
</details> 

<details> 
  <summary>CQRS 패턴 적용</summary>

  Front 개발자 분들과 협업을 하며 조회 관련한 쿼리 로직들이 빈번하게 변경이 되는 반면 Command 관련한 로직은 변경이 되지 않는 것을 확인했습니다.  
  이에 따라 Command 와 Query Service를 변경하여 보다 변경을 편리하게 할 수 있도록 CQRS 패턴을 적용했습니다. 

  - [Diary Command Service](https://github.com/Lovely-4K/love-backend/blob/dev/api/src/main/java/com/lovely4k/backend/diary/service/DiaryService.java#L32-L160)
  - [Diary Query Service](https://github.com/Lovely-4K/love-backend/blob/dev/api/src/main/java/com/lovely4k/backend/diary/service/DiaryQueryService.java#L16-L47)
  
</details> 



## 5. 핵심 트러블 슈팅

<details>
  <summary> Spring Session에서 JWT 변환 </summary>
  
  - 기존 상황 
    - 소셜 로그인 성공 시 WAS의 end-point("/")로 redirect 
    - 소셜 로그인 성공 후 Session 방식으로 로그인 관리
  - 문제 발생
    - (정책 변경) 소셜 로그인 성공 후 Front Server로 redirect
    - 기존에 사용하던 Session 방식 사용 시 Backend Server로 Session 값을 보내지 못하는 현상 발생
  - 문제 원인
    - Cookie의 `SameSite=Lax` 설정이 원인
    - `SameSite=Lax`의 경우 다른 도메인간 쿠키가 전달되지 않음
  - 문제 해결
    - `SameSite=None` 설정의 경우 다른 도메인간 전달이 가능하나 https 통신이 필요함
    - front 팀원들이 주로 테스트 하는 환경은 http
    - JWT의 경우 다른 도메인간에 전달이 가능하며 별도로 https 환경이 따로 필요하지 않았음
    - 소셜 로그인 성공시 url에 access token 값을 같이 보내주는 것으로 문제를 해결함
</details>

<details>
  <summary> Rest Docs 문서가 생성되지 않는 현상 </summary>

  
  - 문제 발생
    - EC2에 띄운 jar의 경우, asciidoctor로 생성한 문서에 접근을 할 수 없는 현상 발생
    - 해당 jar 파일을 압축 해재해본 결과 생성한 문서 파일이 존재 하지 않음을 확인
  - 문제 원인
    - gradle build 과정에서 문서가 생성되기 전에 jar를 만들어 jar 파일 내에 asciidoctor 문서가 생성되지 않음
  - 문제 해결
    - bootJar 내에 `dependsOn` 명령어를 사용해 문서 생성이 먼저 될 수 있도록 빌드 과정 순서를 변경해 문제 해결

  [ 관련 링크 ](https://tommykim.tistory.com/79)
</details>
  
</br>

## 6. 그 외 트러블 슈팅

<details>
  <summary> Github Actions 테스트에서 Credential 설정 관련 테스트 깨짐 현상 </summary>

  - 문제 발생
    - 프로젝트에서 비밀 값들은 github에 올리 지 않고 별도의 파일로 관리했습니다.
    - CI 단계에서 Github Actions를 통해 테스트를 수행하는데, 비밀값을 읽지 못해 테스트가 깨지는 현상을 발견했습니다.
  - 해결 방안
    - Github에 비밀 값들을 저장하고, Github Actions 동작 과정에서 `echo` 를 통해 환경변수를 집어넣어주는 방식으로 문제를 해결했습니다. 
</details>
